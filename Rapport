\documentclass[a4paper,10pt]{article}
%\documentclass[a4paper,10pt]{scrartcl}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage{float}

\title{Rapport Systèmes et Réseaux II}
\author{Perion Maxence, Pinon Alexandre}
\date{}

\renewcommand*\contentsname{Sommaire}
 \renewcommand{\listfigurename}{Liste des images}%

\pdfinfo{%
  /Title    ()
  /Author   ()
  /Creator  ()
  /Producer ()
  /Subject  ()
  /Keywords ()
}

\begin{document}

\maketitle 
\tableofcontents

\newpage
\section{Introduction}
L'objectif de ces Travaux Pratiques a été de réaliser un serveur complet pour une agence fictive. Pour cela, nous étions en possession de deux machines: un serveur/routeur ainsi qu'un client, une machine simulant la connexion d'un appareil au réseau de l'agence. Nous sommes partis de zéro et dans un premier temps nous avons installé Debian sur notre serveur, une distribution GNU/Linux, sans interface graphique via le réseau IEM pour avoir un outil de travail. Nous avons premièrement défini et paramétré notre adressage et routage, c'est à dire la façon d'attribuer les adresses IP et comment communiquer sur les différents réseaux. Afin de s'affranchir des adresses IP et pour s'approcher d'un cadre plus réaliste, nous avons deuxièmement mis en place sur le serveur un service de DNS, permettant d'utiliser des noms de domaines agissant comme des alias pour des adresses IP.  Troisièmement, nous avons mis en place ce qui pourrait servir pour héberger un site web pour notre agence grâce à une suite d'outils appelée un LAMP. Pour finir, nous avons mis en place un service d'authentification centralisé LDAP ainsi qu'un service de partage de fichiers Samba.

\section{Installation d'une distribution GNU/Linux sans interface graphique}

\subsection{Installation via le réseau}

Pour commencer à travailler, la première étape a été d'installer un système d'exploitation: une distribution GNU/Linux sans interface graphique, à savoir Debian dans sa version "Bullseye" (Debian 11). Sans celui-ci, il nous serait impossible de réaliser la moindre tâche avec notre serveur. Le fait qu'il s'agisse d'une distribution Linux va nous permettre de pouvoir manipuler les différents services autant que nous le souhaitons, avec un système de paquets très pratiques. Afin d'installer cette distribution, les administrateurs Systèmes et Réseaux nous ont mit à disposition un boot via le réseau. En temps normal pour installer un système d'exploitation, quel qu'il soit, les utilisateurs utilisent des clés USB ou un disque dur qui permette de démarrer sur celui-ci et d'installer le système d'exploitation à partir de la. Le principe est le même dans notre cas sauf que cette installation se fait par le réseau IEM qui est le réseau de l'université de Bourgogne. Pour lancer l'installation nous devions brancher notre serveur sur le réseau et le démarrer depuis le bios en sélectionnant le bouton "PXE IEM". Une fois l'installation démarrée nous devions suivre les étapes d'installation, telles que définir le nom et mot de passe du root, choisir/créer des partition du disque dur, donner un nom à la machine, ... 

\subsection{Partitions du disque}

Lors de l'installation du système d'exploitation il est nécessaire de réaliser des partitions du disque dur pour scinder son espace de mémoire afin d'être utilisé pour différentes choses en simultané et sans risque de collisions ou de chevauchements. Notre disque après l'installation est désormais composé de 3 partitions et il est possible de les afficher ainsi que des détails supplémentaires avec la commande:
\begin{lstlisting}[language=bash]
  $ sudo fdisk -l
\end{lstlisting}

 % partitionDisque.PNG: 1115x234 px, 96dpi, 29.51x6.19 cm, bb=0 0 836 176
\begin{figure}[!h]
\centerline{\includegraphics[width=15cm]{images/partitionDisque.PNG}}
\caption{Les 3 partitions d'un disque}
\label{fig1}
\end{figure}

Sur la figure \ref{fig1}, nous pouvons voir distinctement les différentes partitions, dont la partition générale sda1 de 237.5 Go qui nous permet de stocker différents fichiers tels que des paquets pour l'utilisation de Debian ou encore différents fichiers de configuration par exemple. De plus, nous pouvons voir la partition qui permet le mécanisme de swap. Il s'agit d'un mécanisme du système d'exploitation qui va se servir du disque dur pour stocker des informations normalement stockées dans la RAM, lorsque celle-ci est saturée. Il y a également un partition étendue qui est un conteneur de partitions logiques: sda2. Maintenant que Debian est installé sur notre routeur, il est prêt à être configuré et utilisé pour différentes tâches. 

\subsection{Synthèse des commandes du gestionnaire de paquets}
Sous Debian il existe de multiple gestionnaires de paquets, tels que aptitude, apt et dpkg. Dans notre cas, nous avons utilisé ``apt-get".
Il est important de comprendre que les outils de gestion des paquets Debian de plus haut niveau comme aptitude, apt-get ou synaptic reposent sur apt qui, lui-même, utilise dpkg pour la gestion des paquets sur le système.

\subsubsection{Mise à jour du système}
Il est possible de mettre à jour le système avec le gestionnaire de paquets ``apt-get", en étant connecté en tant que root ou en préfixant les commandes avec sudo. Auparavant, on utilise la commande ``update" qui permet d'actualiser la liste des paquets disponibles pour le système, à partir du dépôt de paquets. Le dépot de paquet est un service sur un serveur distant, contenant les fichiers des paquets à mettre à jour ou à installer. On lance la commande avant d'installer un nouveau paquet ou avant d'installer les mises à jour du système. Elle ne modifie pas le système, elle demande simplement s'il existe de nouveaux paquets ou des nouvelles versions de paquets. On utilise cette commande de cette façon en tant que root: 
\begin{lstlisting}[language=bash] 
    $ apt-get update
\end{lstlisting} 
Ou pour un utilisateur qui n'a pas tous les droits:
\begin{lstlisting}[language=bash] 
    $ sudo apt-get update
\end{lstlisting} 
Cette étape n'est pas nécessaire mais c'est un bon réflexe à avoir avant de mettre à jour tous les paquets.

S'il y a des paquets à mettre à jour, alors on peut utiliser la commande ``upgrade" pour les installer à partir des fichiers stockés sur les sources énumérées. De nouveaux paquets seront installés si cela est nécessaire, mais les paquets installés ne seront jamais supprimés.
\begin{lstlisting}[language=bash] 
    $ apt-get upgrade
        ou
    $ sudo apt-get upgrade
\end{lstlisting}

Afin de mettre à jour l'ensemble du système, il est possible d'utiliser ceci:
\begin{lstlisting}[language=bash] 
    $ apt-get dist-upgrade
\end{lstlisting}
Il est recommandé d'installer les dernières versions de paquets disponibles pour le système utilisé que ce soit Linux, Windows ou autres. Cela permet de corriger des bugs et d'installer des correctifs de sécurité.

\subsubsection{Les paquets}
Afin d'administrer correctement un système GNU/Linux Debian, voici une liste non exhaustive des commandes de gestion de paquets de Debian à connaître.

\begin{itemize}
\item
\begin{lstlisting}[language=bash] 
    $ apt-cache search <expression rationnelle> 
\end{lstlisting}
Pour rechercher un paquet il est possible d’utiliser la commande "search", cette dernière recherche un paquet à partir d’une expression rationnelle. La recherche porte sur le nom et la description du paquet.
 
\item
\begin{lstlisting}[language=bash] 
    $ apt-cache show <paquet> 
\end{lstlisting}
Pour afficher des informations détaillées concernant un paquet.

\item
\begin{lstlisting}[language=bash] 
    $ apt-cache policy <paquet>
\end{lstlisting}
Pour afficher les versions disponibles d'un paquet.

\item
\begin{lstlisting}[language=bash] 
    $ apt-get install <paquet>
\end{lstlisting}
L'installation d'un paquet disponible sur les serveurs, qui sera couramment utilisé durant nos installations.

\item
\begin{lstlisting}[language=bash] 
    $ apt-get remove <paquet>
\end{lstlisting}
Si nous avons besoin de désinstaller un paquet, on peut utiliser ceci. De plus, la désinstallation d'un paquet avec cette commande ne supprime pas les fichiers de configuration éventuel, ce qui permet de ne pas perdre sa configuration si on est amené à le réinstaller plus tard.

\item
\begin{lstlisting}[language=bash] 
    $ apt-get purge <paquet>
\end{lstlisting}
A contrario ici le paquet est désinstallé avec tous les fichiers de configuration.

\item
\begin{lstlisting}[language=bash] 
    $ apt-get autoremove
\end{lstlisting}
Supprimer les paquets installés automatiquement lorsqu'ils ne sont plus nécessaires.

\item
\begin{lstlisting}[language=bash] 
    $ apt-get clean
\end{lstlisting}
Nettoyer complètement le dépôt local des fichiers de paquets récupérés.

\item
\begin{lstlisting}[language=bash] 
    $ apt-get autoclean
\end{lstlisting}
Nettoyer le dépôt local des fichiers des paquets périmés.\\
 
Et il y a évidemment les différentes mises à jour vues précédemment.
\item
\begin{lstlisting}[language=bash] 
    $ apt-get update
    $ apt-get upgrade
    $ apt-get dist-upgrade
\end{lstlisting} 
\end{itemize}
Avec toutes ces commandes, nous sommes fin prêt à mettre en place tout un tas de service divers et variés tel qu'un DNS ou encore un serveur LAMP par exemple.

\section{Paramétrage du réseau}
Pour pouvoir commencer à communiquer entre différentes machines, nous avons ensuite défini la répartition des adresses IP pour chaque groupe (chaque agence) et paramétré en conséquences les différentes interfaces réseaux sur le routeur puis le client. Pour cela, nous nous sommes connectés au réseau IEM via la carte réseau intégrée à la carte mère sur routeur, la première carte réseau externe a été branché au switch afin de permettre la communication avec les autres groupes, donc le réseau d'interconnexion et dernièrement la deuxième carte réseau externe est utilisée pour le réseau privé mais puisque nous n'avons qu'un client, nous l'avons directement connecté. Toutes les connexions ont étés effectuées via des câbles Ethernet standard. Ici le but de la manipulation est de mettre en place un réseau d'entreprise et d'une infrastructure de services.

\subsection{Répartition des adresse IP (réseau d'Interconnexion entre agences et réseau privé de l'agence)}
Chaque binôme du groupe de TP s'est vu attribuer une adresse IP de classe C et un masque qui sera utilisé pour le réseau d’interconnexion. Puisqu'il y a 5 binômes dans notre groupe de TP, nous avons pris une adresse dans la plage allant de 192.168.1.1 à 192.168.1.5. Pour la même raison, nous avons défini le masque du réseau d'Interconnexion à 255.255.255.248, résultat que nous avons obtenu en ajoutant 3 bits à 1 le plus à gauche possible au masque standard de classe C (255.255.255.0). Ces 3 bits supplémentaires nous permettent de coder 2\textsuperscript{3}=8  sous réseaux, ce qui suffit pour nos 5 groupes.
\newline
 % ReseauInterco&Prive.png: 720x310 px, 96dpi, 19.05x8.20 cm, bb=0 0 540 232
\begin{figure}[!h]
\centerline{\includegraphics[width=15cm]{images/ReseauInterco&Prive.png}}
\caption{Tableau des adresses IP de chaque groupe}
\label{fig2}
\end{figure}

\par
Le tableau de la figure \ref{fig2} récapitule les adresses IP allouées pour chaque réseau et pour chaque groupe. Pour notre cas nous sommes dans le groupe 2 ce qui signifie que notre adresse sur le réseau d’interconnexion est 192.168.1.2 et notre adresse de réseau privé est 10.1.2.0.
\newline
\par
Après avoir défini ces adresses et ces réseaux sur le papier, il est désormais temps de configurer les machines afin de les implémenter concrètement.

\subsection{Les interfaces réseaux du routeur}
Les adresses que nous venons de répartir entre chaque groupe et réseaux doivent être utilisées par le routeur. Nous allons donc maintenant expliquer comment nous avons paramétré les interfaces réseaux sur le routeur. Pour cela, nous avons travaillé avec le fichier ``/etc/network/interfaces" qui régit le fonctionnement des interfaces réseaux de la machine au niveau du noyau du système d'exploitation. Une interface réseau correspond à une carte réseau (en général) et il est possible à partir de son nom de la configurer (adresse statique, adresse du réseau, masque, gateway, ...). La gateway d'une telle configuration est la machine qui doit être utilisée pour passer d'un réseau à un autre. En d'autres termes, il s'agit de la ``porte d'accès" à utiliser. Par exemple si une machine du réseau privé veut communiquer avec une autre machine située sur le réseau IEM, elle devra utiliser le serveur pour router ses paquets. Nous avons modifié le fichier pour obtenir le résultat de la figure \ref{fig3}. 

\begin{figure}[!h]
\centerline{ \includegraphics[width=15cm]{images/interfacesRouteur.png}}
\caption{Fichier de configuration des interfaces réseaux du routeur}
\label{fig3}
\end{figure}

Il est possible d'afficher les interfaces réseaux disponibles sur la machine dans le shell avec la commande:
\begin{lstlisting}[language=bash] 
    $ ip a 
\end{lstlisting} 
Cette commande a pour intérêt de connaître rapidement les adresses MAC et/ou IP de chaque interface. Elle nous a permit de connaître le nom des interfaces à utiliser dans notre fichier de configuration mais elle permet également de savoir si une interface est active ``UP" ou non ``DOWN". En effet, durant les phases de tests il était important de savoir quelles interfaces étaient allumées ou éteintes. Il est possible qu'après une mauvaise configuration ou un problème de branchement, une interface soit éteinte. Il existe des commandes utilitaires pour les manipuler, l'une allumant l'interface nommée ``interface'' et l'autre l'éteignant. 

\begin{lstlisting}[language=bash] 
    $ ifup interface
    $ ifdown interface
\end{lstlisting}

Pour le fichier de configuration (figure \ref{fig3} ci-dessus) , nous pouvons voir que nous avons configuré les 3 interfaces (donc les 3 ports Ethernet que possède notre routeur), ainsi que l'interface ``lo" qui représente le loopback. Le loopback est la ``boucle'' locale: c'est une interface virtuelle qui permet de définir à une machine ``elle même'', notamment lors de l'utilisation de l'adresse ``localhost''.  Pour chacune des interfaces, nous avons donc défini leur adresse (address), leur masque (netmask) et leur réseau (network). Pour l'interface ``eno1" qui est relié au réseau IEM, nous avons plusieurs informations supplémentaire: l'adresse de broadcast (adresse utilisée pour transmettre un message à toutes les autres machines d'un réseau), la passerelle (gateway), les dns, ... Nous pouvons voir que l'interface ``eno1" est relier au réseau IEM car pour le réseau nous avons indiqué l'adresse 172.31.20.1 qui est l'adresse du routeur du réseau IEM fournie par les intervenants des travaux pratiques. Le raisonnement est le même pour les interfaces ``enp3s0" et ``enp1s0", pour lesquels nous avons indiqué respectivement pour le réseau les adresses 10.1.2.0 et 192.158.1.0. Il s'agit donc des réseaux d'interconnexion et privé. Les entrées ``dns-nameservers" et ``pre-up" seront expliquées plus en détail ultérieurement. Une fois le fichier de configuration des interfaces réseaux édité à notre souhait, ses informations ne sont pas prises en compte immédiatement: il est nécessaire de redémarrer le service réseau associé, en tant que root ou alors avec sudo:

\begin{lstlisting}[language=bash] 
    $ service networking restart
    ou
    $ /etc/init.d/networking restart
    ou
    $ systemctl restart networking
\end{lstlisting}
Ces 3 commandes permettent de façon similaire de redémarrer le service réseau. 
\newline
\par Cependant, ces configurations sur le routeur ne sont pas les seules nécessaires pour que tous les réseaux fonctionnent: il est également nécessaire de configurer la machine client qui est connectée au réseau privé, notamment pour qu'elle connaisse comment communiquer avec une machine du réseau d'interconnexion ou du réseau IEM.

\subsection{Les interfaces réseaux du client}

Nous allons maintenant expliquer comment nous avons paramétré les interfaces réseaux sur le client. De la même manière que pour le routeur, le fichier de configuration se trouve dans /etc/network/interfaces et sa forme est identique a celui du routeur. Cependant, cette fois il n'est nécessaire de configurer qu'une seule interface, la seule qui est utilisée et qui est connectée au routeur par le réseau privé. Les informations que nous retrouvons dans ce fichier sont les suivantes. On peut y retrouver l'adresse de la machine, le masque et le réseau, ainsi que la gateway.

\begin{lstlisting}[language=bash]
    auto enp11s0
    iface enp11s0 inet static
                address 10.1.2.2
                netmask 255.255.255.0
                network 10.1.2.0
                gateway 10.1.2.1
\end{lstlisting}

On voit ici que l'IP renseigné pour le réseau de l'interface ``enp11s0" est 10.1.2.1, qui est l'adresse de notre sous réseau. L'adresse IP de notre client est désormais fixée à 10.1.2.2.
Comme pour le routeur, afin d'appliquer les changements il faut redémarrer le service avec l'une des trois commandes évoquées précédemment. Par la suite, toutes ces configurations vont permettre au client et au routeur de communiquer avec le reste des machines des autres groupes. 

\subsection{Communication basique sans table de routage}

Nous allons maintenant aborder la communication entre différentes machines, car nous avons pour but de simuler un réseau en entreprise, et par conséquent il faut que nos machines puissent communiquer. Il est également nécessaire que le routeur soit en capacité de rediriger correctement les paquets des machines la où ils doivent être conduits. Par défaut, le client et le routeur peuvent communiquer car ils sont branchés physiquement entre eux. Il en est de même pour tous les routeurs qui sont branchés sur le réseau IEM car ils sont tous sur le même réseau. Afin de tester les communication entre différentes machines, que ce soit routeurs ou clients, nous pouvons essayer de ping la machine, à condition que le protocol soit activé sur la cible, avec cette commande:
\begin{lstlisting}[language=bash]
  $ ping ip_machine
\end{lstlisting}

Pour montrer le bon fonctionnement jusqu'ici, nous allons avec notre routeur, essayer de ping le routeur d'un autre groupe via le réseau IEM:

\begin{figure}[!h]
\centerline{ \includegraphics[width=15cm]{images/routeurPingRouteur.png}}
\caption{Ping de notre routeur à un autre}
\label{fig4}
\end{figure}

Nous pouvons voir sur la figure \ref{fig4} que les paquets sont bien envoyés et reçus par notre correspondant et tout s'est bien déroulé. Cependant si notre routeur ou notre client veut ping ou plus globalement communiquer avec un client d'un autre groupe qui est donc sur un autre réseau privé, nous allons devoir lui indiquer le chemin pour aller jusqu'à celui-ci, ce qui est réaliser avec un table de routage.

\subsection{Mise en place de la table de routage}

L'étape suivante est la création de routes afin de permettre la communication entre les différentes machines de la simulation: le client et le routeur, mais également entre chaque routeurs (les autres agences) et entre différents clients de différentes agences.
\par
Dans la configuration actuelle, il nous est impossible de ping le client qui est connecté ``derrière'' un autre routeur que le notre, car notre routeur ne connaîtra pas de chemin (route) par lequel acheminer les paquets vers cette cible. Pour arriver à faire ceci, il nous faut mettre en place une table de routage.
Il s'agit d'une table qui permet d'indiquer les routes possibles pour atteindre certains réseaux et avec une adresse de redirection dite de ``default'' qui indique vers qui envoyer le paquet si on ne connaît pas de chemin. Si aucun chemin n'est trouvé, l'erreur ``Network Unreachable'' sera renvoyé à l'émetteur du paquet. 

Il est possible d'afficher les routes de notre routeur dans le shell avec la commande:
\begin{lstlisting}[language=bash] 
    $ ip route
\end{lstlisting} 

\begin{figure}[!h]
\centerline{ \includegraphics[width=15cm]{images/routeRouteur.png}}
\caption{Route de notre routeur}
\label{fig5}
\end{figure}

Nous pouvons voir sur la figure \ref{fig5} que la route par défaut à emprunter pour tous les paquets qui arrivent, si aucune des routes décrites ne convient, est la route par l'adresse 172.31.20.1. Il s'agit de l'adresse du routeur du réseau IEM, qui va à son tour regarder dans ses tables (ou non si le destinataire est directement accessible) une route correspondante ou utiliser sa route par défaut et ainsi de suite. Nous pouvons également voir que les paquets à destination du réseau 10.1.2.0/24 sont dirigé vers l'adresse 10.1.2.1. Il s'agit de l'adresse de notre serveur mais sur le réseau privé: le paquet est donc routé par une autre interface afin d'atteindre le sous réseau privé de destination. Le principe est le même pour le réseau d'interconnexion, et le réseau IEM qui sont également redirigés vers d'autres interfaces sur le serveur mais qui sont toutes différentes. Pour finir, nous pouvons voir que le traffic n'ayant pas trouvé de route sera envoyé vers l'adresse du routeur du réseau IEM (route par défaut).
\newline
\par
Les routes statiques sont ajoutées dans le noyau de notre serveur par l'intermédiaire de la commande ip route, utilisée en tant que root ou avec sudo dans le cas contraire: 
\begin{lstlisting}[language=bash] 
    $ ip route add {network} via {IP}
\end{lstlisting}

Ces routes fonctionnent pour notre réseau privé, le réseau d'interconnexion ou le réseau IEM. Cependant, elles ne nous permettent toujours pas de communiquer avec un router connecté derrière le serveur d'un autre groupe. Pour cela,  il va nous falloir ajouter encore une route et de la même façon il nous faudra une route pour chaque groupe avec lequel nous souhaitons communiquer. Le groupe avec qui nous effectuons les tests ont pour adresse (leur serveur) sur le réseau d'interconnexion l'adresse IP 192.168.1.1 et pour adresse de leur réseau privé 10.1.1.0. L'adresse IP de leur client dans leur réseau privé est 10.1.1.1.
\newline
Pour pouvoir communiquer avec une machine sur leur réseau privé, nous devons donc appliquer sur notre routeur la commande : 
\begin{lstlisting}[language=bash] 
    $ ip route add 10.1.1.0/24 via 192.168.1.1
\end{lstlisting}
Cette commande permet de dire que tout ce qui est à destination de leur réseau privé, d'adresse IP 10.1.1.0, doit être redirigé vers la machine ayant l'adresse 192.168.1.1, c'est à dire leur routeur. Leur routeur sera alors atteint en empruntant le réseau d'interconnexion. Nous pouvons désormais, avec notre routeur, taper la commande qui permet de ping leur client:
\begin{lstlisting}[language=bash] 
    $ ping 10.1.1.1
\end{lstlisting}
Le ping du client de leur réseau privé fonctionne désormais: nos paquets sont bien envoyés et réceptionnés. 

\subsection{Règles iptables pour laisser l'accès a internet a une machine}

L'architecture de notre réseau commence à prendre forme, mais un client sur notre réseau privé ne peut toujours pas accéder à internet: pour le moment seul le routeur est connecté à internet à travers le réseau IEM. Pour réaliser cette manoeuvre appelée une translation d'adresse, nous allons utiliser les règles "iptables":

\begin{lstlisting}[language=bash] 
    $ iptables -t nat -A POSTROUTING -s 10.1.2.0/24 
    -o eno1 -j MASQUERADE
\end{lstlisting}

Cette commande permet d'indiquer au routeur qu'il doit retransmettre les paquets reçus du réseau privé (source 10.1.2.0/24) sur le réseau IEM (interface de sortie "eno1"). L'option masquerade permet d'indiquer que le paquet sera retransmis par translation d'adresse, c'est à dire que le routeur va stocker dans son noyau les informations sur l'émetteur de ce paquet (adresse, port, ...) puis va l'émettre à nouveau en son nom. Lorsque le routeur recevra une réponse, il pourra consulter la table de translation dans son noyau pour trouver à qui il doit transférer le paquet.
\newline
\par
Afin de vérifier si notre routeur était capable d'utiliser internet, nous avons installé "links2" qui a été auparavant installé via le gestionnaire de paquet "apt". Il s'agit d'une commande qui permet de consulter des pages web avec un affichage non graphique, que nous utilisons avec la commande: 
\begin{lstlisting}[language=bash] 
    $ links2 google.com
\end{lstlisting}
Et en effet, notre routeur était capable de surfer sur le web. Nous avons également appliqué cette procédure pour notre client afin de vérifier si il était connecté à internet.
\newline\newline
\par
L'inconvénient de cette nouvelle règle iptable est que n'importe quel client qui arrive à se connecter au réseau privé peut avoir accès à toutes les ressources et se connecter au réseau IEM ou d'interconnexion. Nous pouvons restreindre l'accès à notre réseau privé en n'attribuant une adresse IP qu'à certaines adresses MAC connues, via le service DHCP.

\section{Service DHCP}
Maintenant partons du principe que nous souhaitons connecter plusieurs clients sur notre réseau privé, il est alors important d'approfondir le paramétrage de notre réseau avec la mise en place d'un service DHCP afin de définir les adresses IP à attribuer pour les machines (clients) se connectant sur notre réseau privé.
\subsection{Mise en place du DHCP}

Avant toute chose, nous avons cherché et installé le bon paquet pour l'utilisation du DHCP:
\begin{lstlisting}[language=bash] 
    $ apt-get install isc-dhcp-server
\end{lstlisting}
Une fois l'installation effectuée, nous nous sommes rendu dans le fichier /etc/default/isc-dhcp-server qui a été installé avec le paquet via la commande décrite précedemment. Dans ce fichier de configuration, il faut renseigner avec quelle interface réseau nous voulons travailler pour la suite de la mise du DHCP.

\begin{figure}[!h]
\centerline{\includegraphics[width=15cm]{images/dhcpServeur.png}}
\caption{Interface du DHCP}
\label{fig6}
\end{figure}

Puisque nous voulons allouer automatiquement l'adresse IP de chaque client connecté à notre réseau privé nous avons utilisé l'interface ``enp3s0", qui est celle utilisée pour notre réseau privé. Nous travaillons uniquement en IPv4 donc nous avons laissé vide les interfaces pour IPv6.
\newline
\par
Ceci étant fait, nous pouvons désormais passer au paramétrage en détails du serveur DHCP, comme par example la plage d'adresse IP qui va être subnetée, ou encore fixer des adresses IP pour des postes ayant des adresses MAC définies. Cette configuration du serveur DHCP se fait sur le fichier ``/etc/dhcp/dhcpd.conf".

\begin{figure}[!h]
\centerline{ \includegraphics[width=15cm]{images/dhcpdConfServeur.png}}
\caption{Configuration du serveur DHCP}
\label{fig7}
\end{figure}

Sur la figure \ref{fig7} nous pouvons voir que le réseau subneté est notre réseau privé ayant comme adresse 10.1.2.0 et le masque 255.255.255.0. Nous attribuons une adresse fixe à plusieurs clients car durant nos tests il est arrivé que nous ayons des clients différents et sans cela, il aurait été impossible pour le cient de se connecter au réseau privé. Afin d'attribuer une adresse fixe, il suffit d'indiquer l'adresse qu'on lui fixe avec comme entrée ``fixed-address" ainsi que son adresse MAC ``hardware ethernet".
Nous avons également renseigné différentes informations concernant le DNS mais nous aborderons le sujet plus tard.

De la même façon que pour les interfaces réseaux, quand une modification est apportée il faut redémarrer le service correspondant afin de prendre en compte les changements effectués, avec la commande:

\begin{lstlisting}[language=bash] 
    $ service isc-dhcp-server restart
\end{lstlisting}

Il est également possible de démarrer le service, si il est arrêté, avec:
\begin{lstlisting}[language=bash] 
    $ service isc-dhcp-server start
\end{lstlisting}
Ou a contrario nous pouvons le stopper si besoin avec:
\begin{lstlisting}[language=bash] 
    $ service isc-dhcp-server stop
\end{lstlisting}
Il est également possible d'afficher les erreurs en cas de soucis avec:
\begin{lstlisting}[language=bash] 
    $ cat /var/log/syslog
\end{lstlisting}
Et finalement on peut afficher l'interface d'écoute du démon par l'intermédiaire de la commande:
\begin{lstlisting}[language=bash] 
    $ ps ax | grep dhcpd
\end{lstlisting}
En cas de problème ou pour simplement monitorer ce qu'il se passe sur notre serveur, il peut être intéressant de garder une trace de ce qu'il se passe avec le service. Pour cela, nous avons besoin de mettre un place un système de logs dans notre DHCP.

\subsection{Système de logs pour le DHCP}
En réalité, notre service DHCP écrit déjà des logs et ce sont que nous n'ayons rien à configurer. Cependant, ces logs sont écrits avec ceux d'autres services dans les logs du système: syslog. Pour les obtenir dans un fichier spécialement dédié, nous devons modifier, ou plutôt ajouter une configuration à syslog.
\begin{figure}[H]
\centerline{ \includegraphics[width=13cm]{images/dhcpLogsConf.png}}
\caption{Fichier de configuration de syslog}
\label{fig14}
\end{figure}
Pour cela, nous avons modifié le fichier de configuration /etc/rsyslog.conf pour y ajouter ``local7.*   -/var/log/dhcpd.log" comme nous le montre la figure \ref{fig14}. Le tiret avant le chemin du fichier n'est pas la par hasard: il sert à indiquer à syslog d'effectuer une écriture asynchrone: mettre en pause le processus à chaque fois que nous devons effectuer une écriture pour les logs peut se révéler très gourmand sur les performances de la machine et le tiret indique que ce n'est pas nécessaire.\\\\

Nous pouvons voir sur la figure \ref{fig7} que lors de la configuration initiale du serveur DHCP, nous avions ajouté ``log-facility local7;" afin de définir les logs sur l'entrée 7, qui est par défaut pour les logs du réseau. C'est grâce à cela que nous avons pu le mettre en correspondance dans syslog, qui lui définit le fichier dans lequel écrire.\\\\

Pour finir cette configuration, nous avons créé le fichier dans lequel nous souhaitons écrire nos logs, en tant que  ``/var/log/dhcpd.log". Nous lui avons donné le propriétaire ainsi que les droits nécessaires avec les commandes : 
\begin{lstlisting}[language=bash] 
    $ sudo touch /var/log/dhcpd.log
    $ sudo chown syslog:adm /var/log/dhcpd.log
    $ sudo chmod 0640 /var/log/dhcpd.log
\end{lstlisting}

Il a finalement été nécessaire de vérifier que tout fonctionnait bien en regardant si des informations étaient effectivement écrites dans ce fichier. La figure \ref{fig15} en montre un petit extrait. On peut d'ailleurs y voir le client tenter de se connecter (DHCPDISCOVER) et que l'adresse 10.1.2.2 lui est proposée (DHCPOFFER).
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/dhcpLogsExample.png}}
\caption{Fichier de configuration de syslog}
\label{fig15}
\end{figure}

\section{Sauvegarde automatique}
\subsection{Rsync}
Les fichiers importants tels que les logs ou les données sont souvent sauvegardés afin de pouvoir les récuperer en cas de problèmes. Pour mettre en place une telle sauvegarde, nous avons utilisé un paquet nommé ``rsync" qui permet la synchronisation de fichiers. De plus, il est utilisé pour mettre en place des systèmes de sauvegardes distantes ou de points de restauration du système, ce qui est parfaitement ce que nous cherchons pour notre serveur.
La commande de base pour utiliser rsync se fait par :
\begin{lstlisting}[language=bash] 
    $ rsync source/ destination/
\end{lstlisting}
Cette commande va sauvegarder tous les fichiers d'un répertoire source dans un autre répertoire destination.
Cependant, dans notre cas nous allons pousser un peu plus loin et utiliser SSH afin de synchroniser nos fichiers à distance sur une autre machine. Le protocole SSH permet d'établir une communication chiffrée entre une machine locale (le client) et une machine distante (le serveur). Pour utiliser SSH, il est nécessaire de l'installer via le gestionnaire de paquets, et le paramétrer via les commandes :
\begin{lstlisting}[language=bash] 
    $ sudo apt install openssh-serveur
    $ ssh-keygen
    $ ssh-copy-id -i ~/.ssh/id_rsa.pub etudiant@10.1.2.2
\end{lstlisting}   
Comme expliqué précédemment, une fois l'installation de SSH terminée, il nous faut générer une paire de clé public et privée d'authentification (ssh-keygen) qui vont être enregistrés dans les fichiers ``/.ssh/id\_rsa" pour la clé privée et "/.ssh/id\_rsa.pub" pour la clé public. Une fois les clés générées avec succès, nous allons les utiliser pour se connecter en SSH à notre client. La commande ssh-copy-id facilite la connexion par clé SSH, ce qui supprime le besoin d'un mot de passe pour chaque connexion. Une fois la connexion au client correctement configuré, on peut l'utiliser avec rsync afin de sauvegarder les fichiers que nous voulons sur le client. Voici la manipulation de base à effectuer: 
\begin{lstlisting}[language=bash] 
    $ rsync -avz -e ssh chemin/source/ 
        user@ip:"/chemin de destination/"
\end{lstlisting}   
Et dans notre cas nous utilisons précisement:
\begin{lstlisting}[language=bash] 
    $ rsync -avz -e ssh /etc 
        etudiant@10.1.2.2:/home/etudiant/Bureau/backup/
\end{lstlisting}   
Le serveur est capable dorénavant de sauvegarder l'ensemble de sont répertoire "/etc" dans le répertoire "/home/etudiant/Bureau/backup/" de notre client, simplement via l'utilisation de rsync par SSH. Mais il est encore plus intéressant de se demander comment automatiser totalement cette sauvegarde. 

\subsection{Cron}
Dans le monde de l'informatique, l'automatisation de tâches est très souvent recherchée pour gagner du temps et ne plus s'occuper des tâches automatisées. C'est pour cette raison que nous allons utiliser en plus de rsync et SSH un programme nommé ``cron". Cron est un programme qui permet d'exécuter automatiquement des scripts, des commandes ou des services à une date et une heure spécifiée précise, ou selon un cycle défini à l’avance. Cron est parfois appelé ``gestionnaire de tâches planifiées" ou ``planificateur de tâches". Chaque utilisateur à un fichier crontab, lui permettant d'indiquer les actions à exécuter et leur fréquence. Dans notre cas nous allons utiliser le fichier crontab de l'utilisateur ``root".
La commande : 
\begin{lstlisting}[language=bash] 
    $ crontab -e 
\end{lstlisting}   
est utilisée afin d'éditer les actions grâce au fichier crontab, qui s'ouvre après avoir défini un éditeur de texte à utiliser la première fois qu'on lance cette commande.
Dans le fichier crontab, nous allons renseigner cette ligne qui reprend ce qui a été expliqué précédemment avec rsync et SSH : 
\begin{lstlisting}[language=bash] 
        0 15 * * * rsync -avz -e ssh /etc 
            etudiant@10.1.2.2:/home/etudiant/Bureau/backup/
\end{lstlisting}   
Mais nous y ajoutons cette fois ``0 15 * * *", qui indique que nous allons appliquer le principe de rsync et SSH tous les jours de tous les mois à 15h et 0 minute. En effet, le premier paramètre indique les minutes comprises entre 1 et 60, le second indique les heures de 1 à 24, le troisième est pour les jours dans le mois donc de 1 à 31. Et les deux derniers sont pour les mois et jours de la semaines compris entre 1 à 12 pour les mois et 1 (lundi) et 7 (dimanche) pour les jours.

Pour examiner les tâches planifiées de l'utilisateur courant (le contenu du fichier crontab), on peut utiliser:
\begin{lstlisting}[language=bash] 
    $ crontab -l
\end{lstlisting} 
Ce qui nous affiche :
\begin{figure}[!h]
\centerline{ \includegraphics[width=15cm]{images/rsync&crontab.png}}
\caption{Contenu du fichier crontab.}
\label{fig8}
\end{figure}
La mise en place de notre réseau d'entreprise et d'infrastructure est terminée. Pour rappel, nous avons installé une distribution Linux, puis paramétré les bases de notre réseau. Ensuite, nous avons mis en place un service DHCP et finalement une sauvegarde automatique. Nous allons désormais étendre notre réseau et mettre en place un serveur de nom de domaine (DNS). Mais avant de mettre en place le DNS, nous allons regarder comment il fonctionne.

\section{Interrogation d'un DNS}
Avant toute installation, nous avons commencé par comprendre le fonctionnement du DNS. En effet, le DNS (pour Domain Name Serveur en anglais) est un service informatique distribué. Il est utilisé pour traduire les noms de domaine sur Internet avec leurs adresse IP ou autres enregistrements. Pour faire simple, le serveur DNS est un service qui permet d'associer à un site web (ou un ordinateur connecté ou un serveur) une adresse IP. Cette traduction peut se faire dans les 2 sens: trouver une IP à partir d'un nom de domaine mais également de retrouver le nom de domaine à partir de l'IP. Pour la suite de notre installation le DNS va être un composant important de notre réseau. Il est important de rappeler que tous les équipements connectés à un réseau IP, comme Internet, possèdent une adresse IP qui les identifie sur le réseau.

\subsection{Les commandes host, dig et nslookup}
Les serveurs DNS que nous allons interroger ont pour but de montrer les informations qu'il contiennent et ainsi comprendre les bases. Les serveurs DNS que l'on a interrogé durant nos tests, sont interrogés via les commandes : host, dig et nslookup.

La commande host renvoie l’adresse IP et l'adresse MAC associées au nom de domaine, on l'utilise comme ceci
\begin{lstlisting}[language=bash] 
    $ host {nom}
\end{lstlisting} 

Nous l'avons testé avec:
\begin{lstlisting}[language=bash] 
    $ host www.debian.org
\end{lstlisting} 

Qui nous a retourné ceci:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/hostDebian.png}}
\caption{Exemple d'interrogation d'un DNS avec host.}
\label{fig9}
\end{figure}

Sur l'image \ref{fig9}, 2 informations importantes sont données: l'adresse IP du site sur la première ligne avec comme valeur: ``130.89.148.77", et l'adresse MAC sur la seconde: ``2001:67c:2564:a119::77". Voila ce que nous ressort la commande host, voyons maintenant avec dig.
\newline
\par
Dig est également un utilitaire en ligne de commande qui effectue une recherche DNS en interrogeant des serveurs de noms, et on l'utilise de cette façon: 
\begin{lstlisting}[language=bash] 
    $ dig {nom}
\end{lstlisting} 

Nous l'avons testé avec:
\begin{lstlisting}[language=bash] 
    $ dig www.debian.org
\end{lstlisting} 

Qui nous a indiqué:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/digDebian.png}}
\caption{Exemple d'interrogation d'un DNS avec dig.}
\label{fig10}
\end{figure}

Cette fois sur l'image \ref{fig10}, nous obtenons d'avantages d'informations sur le DNS interrogé. Les lignes commençant par ";" sont des commentaires. La première ligne nous indique la version de la commande dig (9.16.22). Dans l’en-tête nous pouvons voir si une réponse a été reçue (ANSWER: 1), afin de savoir si le DNS a répondu ou non. Ensuite la section "QUESTION", nous indique simplement la requête, qui dans ce cas est une requête pour l’enregistrement ``A" de www.debian.org. IN signifie qu’il s’agit d’une recherche Internet. La section "ANSWER" nous indique que www.debian.org a l’adresse IP ``130.89.148.77". Enfin, il y a quelques statistiques supplémentaires sur la requête, comme la date ou la taille du paquets qui contenait le message.

L’utilitaire nslookup (Name System Look Up) est, tout comme les deux autres, un outil qui permet d’interroger directement un serveur de noms et d’en obtenir les informations concernant un domaine. On peut l'utiliser comme ceci: 
\begin{lstlisting}[language=bash] 
    $ nslookup {nom}
\end{lstlisting} 

Nous l'avons testé avec: 
\begin{lstlisting}[language=bash] 
    $ nslookup www.debian.org
\end{lstlisting} 

Qui nous a donc retourné:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/nslookupDebian.png}}
\caption{Exemple d'interrogation d'un DNS avec nslookup.}
\label{fig11}
\end{figure}

Finalement on observe sur l'image \ref{fig11}, que nslookup est à mis chemin entre dig et host. En effet, il nous affiche le serveur qui à interrogé le DNS, et la réponse du DNS en question avec son nom, son adresse IP et son adresse MAC, comme dig mais en plus synthétique. En règle générale avec nslookup nous avons toutes les informations nécessaire.

Que se soit pour host, dig ou encore nslookup, l'indication "{nom}" indique l’adresse IP ou le nom d’hôte du serveur à interroger. Cependant, ils sont utilisables avec d'autres paramètres, comme nous allons le voir juste après.\\\\

L'option "ns" est pour "nameserveur", cela permet d'indiquer où aller (à qui demander) pour trouver l'adresse IP d'un domaine. En effet, le mécanisme consistant à trouver l'adresse IP correspondant au nom d'un hôte est appelé "résolution de nom de domaine". L'application permettant de réaliser cette opération est appelée en anglais "resolver". Lorsqu'une application souhaite se connecter à un hôte connu par son nom de domaine (par exemple "www.debian.org"), celle-ci va interroger un serveur de noms défini dans sa configuration réseau.\\

Voici les différentes requêtes que nous avons essayé: 
\begin{lstlisting}[language=bash] 
    $ host -t ns www.debian.org
    $ dig www.debian.org ns
    $ dig debian.org ns
    $ dig org ns
    $ dig . ns
\end{lstlisting} 

Voyons en détails les réponse renvoyé par la ligne 1 et 2. 
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/hostDebianNS.png}}
\caption{Requête de nameserveur pour un DNS avec host.}
\label{fig12}
\end{figure}

\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/digDebianNS.png}}
\caption{Requête de nameserveur pour un DNS avec dig.}
\label{fig13}
\end{figure}
Nous pouvons immédiatement constater que nous avons interrogé le même DNS afin de comparer les réponses. Comme expliqué précèdement, dig renvoient beaucoup plus de détails sur la requête que host. On observe principalement que la réponse des 2 commandes est identique, mais pour une requête qui aurait besoin de passer par beaucoup plus de nom de domaine, la commande dig serait plus intéressante. En effet, avec dig il est possible d'avoir le nombre de réponses obtenues; ici ``ANSWER: 3" pour ``geo1.debian.org", ``geo2.debian.org" et ``geo3.debian.org". 

Pour conclure, une requête est ainsi envoyée au premier serveur de noms (appelé "serveur de nom primaire"). Si celui-ci possède l'enregistrement dans son cache, il l'envoie à l'application. Dans le cas contraire, il interroge un serveur racine. Le serveur de nom racine renvoie une liste de serveurs de noms faisant autorité sur le domaine. Le serveur de noms primaire faisant autorité sur le domaine va alors être interrogé et retourner l'enregistrement correspondant à l'hôte sur le domaine: dans le cas présent les serveurs ``geo1.debian.org", ``geo2.debian.org" et ``geo3.debian.org". 

L'utilitaire dig avec l'option "+trace" nous donne toutes les redirection, c'est-à-dire les routes par lesquels il est passé. Ce qui nous permet de savoir que 16 serveurs gèrent le ".". Et grâce au site "https://root-servers.org/" on peut savoir que 254 serveurs gèrent le "e".

Finalement, nous pouvons conclure que dig et host renvoie les informations nécessaires identiques, host reste tout de même limité en informations tandis que dig est davantage détaillé. Les 2 commandes peuvent servir, tout dépend du niveau de détails dont on a besoin. 

\subsection{Fichier de renseignement du serveur DNS}
Sur notre serveur, le serveur DNS à utiliser doit être indiqué dans le fichier système: ``/etc/network/interfaces". C'est le même fichier qui renseigne les interfaces réseau. Ce fichier a déjà été évoqué précédemment, mais pas dans sa totalité. En effet, il est temps d'expliquer la ligne suivante: 
\begin{lstlisting}[language=bash] 
    $ dns-nameserveur 172.31.21.35 193.50.50.6
\end{lstlisting}
Cette ligne indique les 2 serveurs de noms de domaine que le système doit utiliser. En réalité le DNS avec l'adresse ``172.31.21.35" est le serveur DNS primaire du réseau IEM, et le DNS avec l'adresse ``193.50.50.5" est le serveur DNS secondaire du réseau IEM. Ces informations sont traités par le ``resolver" qui a été évoqué dans la partie précédente. 

\subsection{Rôle du fichier /etc/hosts}
Ce fichier, existant depuis le début des années 80, a pour rôle d'associer une adresse IP à un nom d'hôte (un nom de domaine n'étant qu'une forme structurée de nom d'hôte). Il est donc présent dans le répertoire ``/etc" et est consulté par le système à chaque fois qu'il accède à un nom d'hôte spécifique. Notons qu'il est consulté avant qu'une requête soit envoyée à un DNS. Aucune autre machine de notre réseau (même local) ne prendra en compte ce qui y est écrit dans celui-ci. Son utilisation est restreinte à de petits réseaux locaux ainsi qu'à quelques autres cas particuliers.

\section{Installation d'un serveur DNS}

Pour la suite des explications, il est important de préciser que nous avons choisi comme nom de domaine: agence.atlantide.

\subsection{Mise en place du DNS}
\subsubsection{Théorie}

Cette partie du rapport est consacré à la mise en œuvre d'un serveur DNS en utilisant ISC BIND (Berkeley Internet Name Domain). Un DNS est une base de données repartie dont la structure est similaire à une arborescence inversée. Le nœud racine est représenté par le ``.''. Une branche complète du type mail.yahoo.fr est appelée FQDN ( Fully Qualified Domain Name) pour nom totalement qualifié. La partie la plus à droite est appelé TLD ( Top Level Domain) et celui le plus à gauche représente l’hôte. Au milieu c’est le domaine. Un serveur de noms définit une zone avec des enregistrements appelés RR pour Ressources Records. Elles constituent les informations fondamentales du DNS. Mais il existe plusieurs types d’enregistrements, chacun possèdant sa propre fonction: 

\begin{itemize}
\item Enregistrement SOA

L'enregistrement SOA (Start Of Authority) retourne des informations officielles sur la zone DNS, incluant la référence du serveur DNS principal (primaire), l'e-mail de l'administrateur, un numéro de série ainsi que divers timers définissant la fréquence de renouvellement et la durée de validité pour certains éléments. Le service de gestion DNS ne propose qu'un seul enregistrement SOA.

\item Enregistrement NS

Les enregistrements NS indiquent quels sont les serveurs qui vont gérer la zone du serveur DNS. Lorsque l'on crée un nom de domaine, pour le relier aux différents services pour lesquels nous allons l’utiliser, nous devons indiquer quels seront les serveurs DNS qui vont héberger les paramétrages de notre zone DNS. Généralement, on utilise 2 ou 3 noms de serveurs DNS : le serveur primaire, mais également un ou deux serveurs secondaires qui peuvent prendre le relais en cas d’indisponibilité du serveur DNS primaire.

\item Enregistrement A

Les enregistrements DNS de type A (également appelés enregistrements d’hôte) permettent de relier un nom de domaine ou un sous-domaine à l’adresse IP d’un serveur.

\item Enregistrement PTR

Les enregistrements de type PTR sont quasiment le contraire des enregistrements A. Au lieu d’assigner une adresse IP à un nom de domaine, ces enregistrements font le contraire. Les enregistrements PTR permettent ainsi un DNS inversé. 

\item Enregistrement MX

MX est l’abréviation de Mail Exchange. Cet enregistrement DNS est différent des autres. L’enregistrement MX est utilisé pour diriger les emails envoyés aux adresses personnalisées associées à un nom de domaine.

\item Enregistrement CNAME

Les enregistrements DNS de type CNAME, appelés aussi enregistrements de noms canoniques, ne résolvent que les domaines et les sous-domaines. Contrairement aux enregistrements A, ils ne peuvent pas être nus (c’est-à-dire qu’il doit y avoir www. devant eux pour que l’URL résolve correctement). 

\end{itemize}

\subsubsection{Pratique}
Passons à la mise en pratique avec l'installation de notre propre serveur DNS. Dans un premier temps, il faut installer les paquets ``bind9" et ``dnsutils" toujours via la même commande et le même gestionnaire de paquets (apt-get).\\

BIND9 peut être utilisé de différentes façons, les plus fréquentes sont :\\

Un serveur cache, dans cette configuration, BIND9 va effectuer les requêtes DNS et se rappeler de la réponse pour la prochaine requête. Cette méthode peut être utile pour une connexion internet lente. En mettant les réponses DNS en cache, on diminue l'utilisation de la bande passante et (encore plus important) on réduit également le temps de latence.\\

Un serveur primaire qui est utilisé pour contenir les enregistrements DNS d'un nom de domaine enregistré. Un ensemble d'enregistrements DNS pour un nom de domaine est appelé une ``zone". (Le nom de domaine peut être imaginaire si on est dans le cas d'un réseau local fermé). Il s'agit du cas d'utilisations que nous allons implémenter.\\

Et finalement un serveur secondaire, qui est un serveur utilisé en complément d'un serveur primaire, en servant de copie à la ou les zones configurées sur le serveur primaire. Les serveurs secondaires sont recommandés sur des gros réseaux. Ceux-ci assurent la disponibilité de la zone DNS, même si le serveur primaire est hors ligne.\\

La première étape consiste à créer 2 zones, une zone dite ``normal" et une zone dite ``inversée'' dans le fichier de configuration ``/etc/bind/named.conf.local". Il est possible d'utiliser le fichier ``/etc/bind/named.conf.default-zones" comme base de travail, que nous copions en notre propre configuration.
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/namedConfLocal.png}}
\caption{Contenu du fichier de configuration named.conf.local.}
\label{fig16}
\end{figure}

Sur l'image \ref{fig16}, les 2 zones sont identifiables par l'identificateur ``zone". La première zone décrite est la zone ``inverse''. Elle a pour nom l’adresse ip ``10.1.2." inversée accompagnée de ``.in-addr.arpa". L'inversion de l'adresse IP est le standard pour décrire une zone ``inverseé''. La seconde zone est la zone ``normale" et que l'on a décrit par le nom de domaine, à savoir ``agence.atlantide". Que ce soit pour la zone ``normale" ou la zone ``inverse" nous indiquons 2 informations: le ``type" pour le type de zone et le fichier de configuration associé avec le mot clé ``file".\\

Afin de mettre en place les 2 fichiers de configuration des 2 zones, nous sommes partis du fichier existant ``/etc/bind/db.local". Celui-ci nous a fournis toutes les informations nécessaires et nous n'avions plus qu'a remplacer les lignes dont nous avions besoin. Par exemple le ``localhost" a été changé en "agence.atlantide", l'adresse IP de loopback (le ``127.0.0.1"), a été changé en ``10.1.2.1".  Nous indiquons ainsi que le nom de domaine agence.atlantide décrit l'adresse ``10.1.2.1'', donc notre serveur.
Pour le fichier de la zone ``normale" nous avons utilisé des enregistrements de type ``A" afin de relier IP et nom de domaine. Nous avons donc un champ A qui définit que le sous domaine client.agence.atlantide décrit l'adresse ``10.1.2.2'', donc notre client.
Voici ci-dessous le fichier "/etc/bind/db.agence.atlantide" de configuration de la zone ``normale":
\begin{figure}[H]
\centerline{ \includegraphics[width=12cm]{images/dbAgenceAtlantide.png}}
\caption{Contenu du fichier de configuration du DNS normal.}
\label{fig17}
\end{figure}

Pour la zone inverse il faut utiliser des enregistrements de type ``PTR" qui permettent la mise en place du DNS inversé. Et voici ici le fichier "/etc/bind/db.agence.atlantide.inv" de configuration de la zone ``inverse":
\begin{figure}[H]
\centerline{ \includegraphics[width=12cm]{images/dbAgenceAtlantideInv.png}}
\caption{Contenu du fichier de configuration du DNS inversé.}
\label{fig18}
\end{figure}

Sur les images \ref{fig17} et \ref{fig18}, la première ligne débutant avec un ``@” permet de définir les informations relatives à la zone (champ SOA). Les ``@” suivants pourront remplacer des noms de machines ou le dernier octet ``host-id” de nos adresses IP.\\

De plus, 2 autres fichiers ont été modifié: le fichier ``/etc/resolv.conf" et ``/etc/bind/named.conf.options". Pour le fichier ``/etc/resolv.conf", afin que les requêtes de résolution des noms passent par BIND. Ce fichier doit donc contenir:
\begin{figure}[H]
\centerline{ \includegraphics[width=10cm]{images/resolvConf.png}}
\caption{Contenu du fichier de configuration de resolv.conf.}
\label{fig19}
\end{figure}

Dans le fichier ``/etc/bind/named.conf.options", nous avons ajouter des forwarders. Dans notre cas, ce sera notre fournisseur DNS (172.31.21.35) du réseau IEM et nous avons changer du paramètre ``dnssec-validation" a ``no". Les forwarders sont les adresses d'autres serveurs DNS qui seront consultés si celui local ne connait pas la réponse. En effet, notre propre serveur DNS ne connait que notre nom de domaine et n'en connaît aucun autre.  Le fichier ``/etc/bind/named.conf.options" contient désormais ces informations:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/namedConfOptions.png}}
\caption{Contenu du fichier de configuration de named.conf.options.}
\label{fig20}
\end{figure}

Après avoir fait toutes ces modifications, il est nécessaire de redémarrer le service BIND, en lançant la commande: 
\begin{lstlisting}[language=bash] 
    $ systemctl restart bind9
\end{lstlisting} 

Pour le DHCP (figure \ref{fig7}), nous avons pris en compte notre nom de domaine  avec l'option ``option domain-name ``agence.atlantide"". Dans ce cas, il sert à faire référence aux ordinateurs du réseau par leurs noms sans ajouter le nom de domaine. Pour faire simple c'est un suffixe DNS. L'option ``option domain-name-servers 192.168.1.2" indique un serveur DNS à l'adresse ``192.168.1.2" (notre serveur sur le réseau d'interconnexion). 

\subsection{Tests réalisés afin de valider le fonctionnement du DNS}
L'installation suivie de la configuration globale du DNS est effectuée, mais avant de l'utiliser sur d'autres machines il est important de vérifier son bon fonctionnement.

Tout d'abord, il faut vérifier la syntaxe des fichiers de configuration. En effet, avant de chercher une quelconque erreur, la syntaxe des fichiers modifiés est la première étape de vérification. Pour vérifier la syntaxe des fichiers de configuration, on peut utiliser 2 commandes:
\begin{lstlisting}[language=bash] 
    $ named-checkzone 
    $ named-checkconf
\end{lstlisting} 

Les fichiers étant syntaxiquement corrects, le serveur DNS peut être démarré (en root) avec ceci:
\begin{lstlisting}[language=bash] 
    $ systemctl start bind9
\end{lstlisting} 

Au moment du démarrage si le serveur DNS renvoie une erreur et ne démarre donc pas, il est possible de voir les détails des erreurs dans le fichier ``/var/log/syslog".\\

Finalement voici une liste de tests effectués afin de tester le DNS:\\
Depuis notre serveur: 
\begin{lstlisting}[language=bash] 
    $ nslookup ip-client
    $ nslookup 10.1.2.1
\end{lstlisting} 

Depuis notre serveur: 
\begin{lstlisting}[language=bash] 
    $ nslookup nom-client
    $ nslookup client.agence.atlantide
\end{lstlisting} 

Depuis un client connecté en filaire à notre routeur: 
\begin{lstlisting}[language=bash] 
    $ nslookup ip-client
    $ nslookup 10.1.2.1
\end{lstlisting} 

Depuis un client connecté en filaire à notre routeur : 
\begin{lstlisting}[language=bash] 
    $ nslookup nom-client
    $ nslookup client.agence.atlantide
\end{lstlisting} 

Vers le serveur d'une autre agence : 
\begin{lstlisting}[language=bash] 
    $ nslookup nom-serveur
    $ nslookup agence.pekin
\end{lstlisting} 

Vers le client d'une autre agence :
\begin{lstlisting}[language=bash] 
    $ nslookup nom-client
    $ nslookup client.agence.pekin
\end{lstlisting} 

Voici différent exemple qui illustre les commandes donné ci-dessus: 
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/exempleNsLookUpDNS.png}}
\caption{Test effectué sur notre DNS avec nslookup.}
\label{fig21}
\end{figure}

Le serveur DNS est fonctionnel et est donc prêt à être utilisé sur d'autres machines, et autres projets.

\section{Installation d'un serveur LAMP}
LAMP est un acronyme: le ``L" désigne Linux: le système d'exploitation, le ``A" désigne Apache: le serveur Web, le ``M" est pour MySQL ou MariaDB: le serveur de base de données, et le ``P" pour PHP: le langage de script.\\

Avec un LAMP, on peut donc mettre en place un serveur Web, hébergeant un site web dynamique écrit en PHP, tout en allant chercher des données dans une base MySQL ou MariaDB, mais également PostgreSQL si nous l'installons optionnellement.

\subsection{Installation et mise en place du LAMP avec MariaDB}
Pour installer le serveur web apache et son module permettant de gérer PHP plus tard, nous utilisons la commande:
\begin{lstlisting}[language=bash] 
    $ apt-get install apache2 libapache2-mod-php
\end{lstlisting} 

Nous avons également utilisé la commande:
\begin{lstlisting}[language=bash] 
    $ systemcl enable apache2
\end{lstlisting} 
Elle permet de démarrer automatiquement le serveur Apache après le boot de notre routeur.\\

Après l'installation (donc par défaut), la page web de notre serveur se trouve à l'emplacement ``/var/www/html/index.html". Et par conséquent, à ce moment de la configuration, nous pouvons déjà visiter la page en visitant avec un navigateur ``http://localhost/index.html" depuis notre serveur.

Pour la suite, nous avons créé un compte pour un utilisateur qui développe des applications web. Cet utilisateur a été créé avec la commande:
\begin{lstlisting}[language=bash] 
    $ adduser dev1
\end{lstlisting} 
Il s'agit d'une commande intégrée nativement à Linux permettant de créer des utilisateurs. Ensuite, nous avons créé le dossier où ce nouvel utilisateur va pouvoir ajouter ses fichiers: ``/srv/dev1". Cependant, l'utilisateur ``dev1" n'a pas les bons droits conçernant ce répertoire par défaut. Nous avons donc également changé les droits et changé le propriétaire du dossier via les commandes:
\begin{lstlisting}[language=bash] 
    $ chown utilisateur nom(s)_de_fichier
    $ chown -R dev1 dev1
    $ chmod -R 755 dev1
\end{lstlisting} 

Ensuite nous avons fait pointer un alias (apache) sur le dossier ``/srv/dev1/www". Pour cela nous avons utilisé le mot clé ``Alias" dans le fichier de configuration d'apache ``/etc/apache2/apache2.conf".
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/apache2Conf.png}}
\caption{Contenu du fichier de configuration de apache.}
\label{fig20}
\end{figure}
La ligne qui nous intéresse est ``Alias ``/dev1" ``/srv/dev1/www"". Cette ligne permet de dire au serveur apache qu'une requête visant ``http://localhost/dev1" est en réalitée à diriger vers ``/srv/dev1/www/".\\

Pour tester notre alias nous avons écrit un petit ``index.html" dans le dossier ``/srv/dev1/www". Nous sommes ensuite passés par ces différentes commandes:
\begin{lstlisting}[language=bash] 
    $ touch /srv/dev1/www/index.html
    $ nano /srv/dev1/www/index.html
\end{lstlisting}

Voici le contenu du fichier ``/srv/dev1/www/index.html" ainsi créé:
\begin{lstlisting}[language=HTML] 
    <html>
        <head>
        <title> DEV 1 WEBSITE </title>
        </head>
        <body>
        <h1>Succes</h1>
        </body>
    </html>
\end{lstlisting} 
Cette petite page HTML nous permet simplement d'avoir un affichage en cas de réussite.\\

Un second utilisateur semblable au premier est créé. Tout comme pour le premier développeur web, nous avons créé un utilisateur ``dev2", ajouté tous les dossiers et fichiers nécessaires et changé les droits. Ce qui nous donne ceci:
\begin{lstlisting}[language=bash] 
    $ adduser dev2
    $ mkdir /srv/dev2
    $ mkdir /srv/dev2/www
    $ touch /srv/dev2/www/index.html
    $ nano /srv/dev2/www/index.html
    $ chown -R dev2 dev2
    $ chmod -R 755 dev2
\end{lstlisting} 
Voici le contenu du fichier ``/srv/dev2/www/index.html":
\begin{lstlisting}[language=HTML] 
    <html>
        <head>
        <title> DEV 2 WEBSITE </title>
        </head>
        <body>
        <h1>Encore un succes</h1>
        </body>
    </html>
\end{lstlisting} 
Dans la même dynamique que la première page, elle est destinée à avoir un affichage de succès pour les phases de test. Nous avons également trouvé le besoin d'utiliser un VirtualHost pour cet utilisateur. En effet, les serveurs virtuels, ou VirtualHost, permettent de faire cohabiter plusieurs serveurs web sur une même machine. Pour créer un VirtualHost, il faut le renseigner dans le fichier ``/etc/apache2/sites-available/dev2.conf". Voici donc la configuration du VirtualHost de dev2:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/virtualHostDev2Conf.png}}
\caption{Contenu du fichier de configuration de dev2.}
\label{fig21}
\end{figure}
Dans ce fichier de configuration nous y retrouvons le chemin du dossier où l'on va mettre nos pages web, ainsi que le nom de domaine utilisé qui est ``informatique.agence.atlantide". Cela permet d'indiquer qu'une requête sur l'adresse ``informatique.agence.atlantide'' est en réalité à destination du dossier ``/srv/dev2/www''. \\

Pour des utilisateurs occasionnels, nous avons mis en place un public\_html afin de publier des
pages personnelles. Nous avons alors activé le module ``userdir" d'apache, qui permet d'accéder à des répertoires spécifiques à l'utilisateur lors de la visite de l'adresse ``http://example.com/\~{} user/". Voici la commande qui a permis d'activer ce module:
\begin{lstlisting}[language=bash] 
    $ a2enmod userdir
\end{lstlisting} 
Pour la suite des manipulations, nous appliquons le même principe que pour les 2 premiers utilisateurs.
\begin{lstlisting}[language=bash] 
    $ mkdir ~/public_html
    $ touch index.html
    $ nano index.html
\end{lstlisting} 
Le \textasciitilde est un raccourci signifiant ``répertoire home de l'utilisateur courant''. Dans notre cas, il s'agit donc de ``/home/dev1/''. \\
Voici le contenu du fichier ``/home/dev1/public\_html/index.html":
\begin{lstlisting}[language=HTML] 
    <html>
        <head>
        <title> PUBLIC HTML </title>
        </head>
        <body>
        <h1>public html succes</h1>
        </body>
    </html>
\end{lstlisting} 
\vspace{2cm}
Le DNS configuré dans la section précedente va être utilisé. C'est la raison pour laquelle dans le fichier ``/etc/bind/db.agence.atlantide", nous avons ajouté la ligne:
\begin{lstlisting}[language=bash] 
    $ informatique IN A 10.1.2.1
\end{lstlisting}
Cela nous permet d'accéder à notre serveur web (contenu créé pour dev1) avec comme nom de domaine ``informatique.agence.atlantide''. Ce changement nécessite le redémarrage du serveur DNS, comme nous l'avons fait précédemment.\\

Une fois toute l'installation terminée, avec les utilisateurs, les droits, les VirtualHosts, les alias et le DNS, nous avons redémarré le serveur apache avec la commande:
\begin{lstlisting}[language=bash] 
    $ systemctl restart apache2
\end{lstlisting} 

Le serveur ainsi configuré est déjà fonctionnel. Nous pouvons brancher un client à notre routeur et visiter les 2 pages suivantes sur un navigateur (firefox, chrome, ...): ``http://agence.atlantide/dev1" pour visiter la page du premier utilisateur, ``http://informatique.agence.atlantide/" pour le deuxième utilisateur. \\ Finalement, la page des utilisateurs occasionnels est disponible à l'adresse ``http://agence.atlantide/~user/". Pour naviguer entre les différents utilisateurs sur notre serveur, il faut utiliser cette commande:
\begin{lstlisting}[language=bash] 
    $ su user
\end{lstlisting} 
Si un mot de passe a été renseigné à la création alors il sera demandé pour se connecter.\\\\

Pour poursuivre l'installation de notre LAMP, il est désormais temps de passer au M, c'est à dire à l'installation de MariaDB.\\

MariaDB est un système de gestion de base de données (SGBD) open source. Pour l'installer avec notre gestionnaire de paquet habituel, il faut utiliser:
\begin{lstlisting}[language=bash] 
    $ apt-get install mariadb-server
\end{lstlisting} 

Nous allons utilisé l'utilisateur root, qui possède tous les droits, pour créer et gérer la base de données. Afin d'utiliser MariaDB, il faut utiliser depuis notre terminal:
\begin{lstlisting}[language=bash] 
    $ mysql -u root 
\end{lstlisting} 
Une fois dans l'invite de commande de MariaDB, on peut alors dans un premier temps créer la base de données, avec:
\begin{lstlisting}[language=bash] 
    mysql> CREATE DATABASE dbtest;
\end{lstlisting} 
Nous avons ainsi procéder à la création d'une base de données MariaDB avec comme nom ``dbtest".\\

Pour être certain qu'elle a été créé nous avons tapé:
\begin{lstlisting}[language=bash] 
    mysql> SHOW DATABASE;
\end{lstlisting} 
Nous pouvons alors voir notre base de données ``dbtest", dans la liste des bases renvoyées par MariaDB. Une fois la base de données établie, il est alors possible de l'utiliser et d'insérer des tables et des données comme une base de données classique. Nous avons essayer ceci:
\begin{lstlisting}[language=bash] 
    mysql> use dbtest;
    mysql> CREATE TABLE test (nom TEXT, prenom TEXT);
    mysql> INSERT INTO test(nom, prenom) VALUES (``NomTest", ``PrenomTest");
    mysql> SELECT * from test;
\end{lstlisting} 
La première ligne indique à MariaDB que nous changeons de base de données et si cela est possible, il nous indique alors ``Database changed". Pour la suite la table de test est nommée ``test" et contient 2 informations (colonnes), un nom et un prénom. La dernière ligne nous renvoie les lignes de la table si il y en a, dans notre cas oui (ajout d'une ligne à la ligne précédente).\\

Afin que PHP puisse interagir avec la base de données, nous avons créé un utilisateur propre à celle-ci. En effet, MariaDB propose la création d'utilisateurs au sein même de son environnement, avec la commande:
\begin{lstlisting}[language=bash] 
    mysql> CREATE USER 'user'@'localhost' IDENTIFIED BY 'password';
\end{lstlisting}

L'utilisateur est alors créé avec comme nom ``user" et mot de passe ``password". Cependant, il ne possède pour l'instant aucun droit et c'est pour cela que nous lui avons donné tous les droits avec:
\begin{lstlisting}[language=bash] 
    mysql> GRANT ALL PRIVILEGES ON * . * TO user; 
\end{lstlisting}
        
Une fois MariaDB installée et fonctionnelle, il ne nous reste plus que PHP. PHP (acronyme récursif de PHP: Hypertext Preprocessor) est un langage de script open source à usage général largement utilisé, particulièrement adapté au développement Web et pouvant être intégré avec HTML.
Toujours dans le même démarche d'installation, il faut cette fois-ci installer PHP:
\begin{lstlisting}[language=bash] 
    $ apt-get install php 7.4
\end{lstlisting}
Une fois l'installation terminée, nous avons créé une page de test dans le répertoire ``/srv/dev2/www/testMariaDb.php". Cette page est éditée avec l'éditeur de texte nano pour contenir ceci:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/testMariaDbPhp.png}}
\caption{Page php de test pour la base de données MariaDb.}
\label{fig}
\end{figure}

Ce petit script php permet de se connecter à la base de données MariaDB avec les identifiants appropriés (Nom de l'hôte, nom de la base de données, nom de l'utilisateur et son mot de passe). Dans le cas où la connexion n'est pas possible alors une erreur est affichée et dans le cas contraire on affiche sur la page le contenu de la base de données.\\\\
La page web est accessible via ``http://informatique.agence.atlantide/testMariaDb.php". Si sur cette page le contenu de base de données MariaDB est affiché (le nom et le prenom de test entrés lors de la configuration) alors le trio Apache MariaDB PHP est fonctionnel.\\
MariaDB n'est pas le seul SGBD utilisable avec PHP et Apache, il en existe d'autres comme nous allons le voir prochainement.

\subsection{Installation et mise en place d'un autre LAMP avec PostgreSQL}
PostgreSQL est un système de gestion de base de données relationnelle et objet.
Ce système est comparable à d'autres systèmes de gestion de base de données, qu'ils soient libres (comme MariaDB ou Firebird) ou propriétaires (comme Oracle, MySQL, Sybase, DB2, Informix ou Microsoft SQL Server). Dans cette partie, PostgreSQL prendra la place de MariaDB. \\

L'installation de PostgreSQL et des paquets PHP compatibles avec PostgreSQL est la première étape:
\begin{lstlisting}[language=bash] 
    $ apt-ge install postgresql postgresql-client
    $ apt-get install php-pgsql
\end{lstlisting}

Pour ce qui est du serveur web Apache, il n'est pas nécessaire de le réinstaller ou de changer sa configuration, de même pour les paramètres globaux du serveur.\\

Pour démarrer la base de données lors du boot du routeur, il existe cette commande:
\begin{lstlisting}[language=bash] 
    $ systemctl enable --now postgresql
\end{lstlisting}

Toutes les modifications doivent se faire avec l'utilisateur ``postgres" qui est créé avec l'installation de PostgreSQL. On se connecte (depuis root) à cet utilisateur avec la commande:
\begin{lstlisting}[language=bash] 
    $ su - postgres
\end{lstlisting}

PostgreSQL ne possède pas de données à cette étape. Nous allons alors créer la base de données pour nos tests, ainsi que l'utilisateur et la table dans la base. Tout ceci est fait à partir des commandes:
\begin{lstlisting}[language=bash] 
    $ su - postgres
    $ psql
    postgres=# createuser user
    postgres=# createdb dbtest -O user
    postgres=# psql dbtest
    postgres=# CREATE TABLE test (nom TEXT, prenom TEXT);
    postgres=# INSERT INTO test(nom,prenom) VALUES ('Postgre','SQL');
    postgres=# SELECT * FROM test;
\end{lstlisting}
Le principe des commandes précèdentes est le suivant: premièrement on passe sur l'utilisateur ``postgres", puis on ouvre le terminal de PostgreSQL. Une fois dans l'invite de commandes de PostgreSQL, on peut alors créer un utilisateur ``user", une base de données ``dbtest" puis une table ``test". Finalement, le fonctionnement est similaire à celui de la base de données MariaDB, le seul changement se trouve dans les valeurs de la table ``dbtest" (afin de pouvoir être sur que c'est à PostregreSQL que nous nous sommes connectés lors de nos tests).\\

Le script suivant permet d'afficher le contenu de la base de données de PostegreSQL et il se situe dans ``/srv/dev2/www/testPostgreSQL.php":
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/testPostgreSQLPhp.png}}
\caption{Page php de test pour la base de données PostegreSQL.}
\label{fig}
\end{figure}

Avec ceci, il est possible de se connecter à la base de données PostegreSQL avec les identifiants appropriés. Encore une fois, c'est le même principe que la base de données MariaDB mais avec une syntaxe différente. Dans le cas où la connexion n'est pas possible alors une erreur est afficheé et dans le cas contraire on affiche sur la page le contenu de la base de données, qui avait été créé lors de la configuration de PostegreSQL. La page web est accessible via ``http://informatique.agence.atlantide/testPostgreSQL.php".

\subsection{Installation et mise en place d'un PDO}
Désormais nous allons installer et mettre en place PDO qui est l'acronyme de PHP Data Objects: c'est une extension PHP permettant d'interagir avec des bases de données via l'utilisation d'objets. L'une de ses forces réside dans le fait qu'il n'est pas strictement lié à une base de données en particulier: son interface offre un moyen commun d'accéder à plusieurs environnements différents, parmi lesquels MySQL et PostgreSQL. En résumé, PDO va nous permettre d'avoir une abstraction des SGBD, et avec ce principe nous avons écrit un script PHP permettant d'afficher le contenu des 2 bases de données précédemment créées. La première étape est l'installation du paquet PDO dans PHP:
\begin{lstlisting}[language=bash] 
    $ apt-get install php-pdo
\end{lstlisting}
Voici donc le script qui est contenu dans ``/srv/dev2/www/testPDO.php", permettant de se connecter aux bases de données et afficher les informations contenues dans celle-ci:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/testPDOPhp.png}}
\caption{Page de test avec PDO.}
\label{fig}
\end{figure}

Ce script se connecte à la base de données MariaDB et affiche le contenu de la table test dans un premier temps puis à la base PostegreSQL dans un second temps pour afficher les informations de la table test. Le script se connecte avec les différents identifiants (Nom de l'hôte, nom de la base de données, nom de l'utilisateur et le mot de passe) aux SGBD. Encore une fois c'est le même principe que les base de données vues précédemment. Dans le cas où la connexion n'est pas possible alors une erreur est affichée, et dans le cas contraire on affiche sur la page le contenue de la base de données en question. La page web est accessible via ``http://informatique.agence.atlantide/testPDO.php".

\section{Script de routage et matrice de filtrage}
Maintenant que nous avons différents services tournant sur notre machine, tels qu'un serveur web, un serveur DNS ou un serveur DHCP, il nous faut désormais réguler le trafic pour sécuriser notre réseau et que seules les personnes qui le doivent peuvent se connecter aux différents services. Les règles de filtrage avec ``iptables" sont parfaitement adaptées pour cette tache. Afin de gérer notre filtrage, nous avons créé deux scripts qui sont ``/etc/firewall-free.sh" et ``/etc/firewall-rules.sh". Le script ``/etc/firewall-free.sh" permet de supprimer les règles pré-existantes (en cas d'erreur ou de problème), il contient seulement:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/firewallFree.png}}
\caption{Contenu du fichier /etc/firewall-free.sh.}
\label{fig}
\end{figure}

Le script ``/etc/firewall-rules.sh" quant à lui contient: 
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/firewallRules.png}}
\caption{Contenu du fichier /etc/firewall-rules.sh.}
\label{fig}
\end{figure}
Ce script appelle le script qui supprime les règles décrit auparavant, mais permet également d'autoriser l'interface loopback, de définir la politique par défaut pour toutes les chaines, de bloquer l'accès d'un autre groupe à notre serveur. De plus, on filtre l'accès au serveur en ouvrant les bon ports, le port 80 fait référence au protocole http. Le port 443 fait référence au protocole https, le port 53 pour le DNS et le port 22 pour SSH. On filtre de la même façon pour le réseau privé avec l'ouverture des ports adéquats. Finalement, on permet le dialogue entre notre client et le serveur, et on permet au client d'aller sur internet.

Nous n'avons pas oublié de rendre ces scripts exécutables à l'aide de la commande:
\begin{lstlisting}[language=bash] 
    $ chmod +x script.sh
\end{lstlisting}

Dans la configuration actuelle les scripts créés ne sont jamais utilisés (il faut les appeler) et c'est pour cela que dans ``/etc/network/interfaces", nous avons ajouté la ligne suivante:
\begin{lstlisting}[language=bash] 
    pre-up /etc/firewall-rules.sh
\end{lstlisting}
Cette ligne permet de dire qu'au démarrage des interfaces réseaux le fichier ``/etc/firewall-rules.sh" est executé. Cela permet donc d'ajouter nos règles de filtrage dans les scripts de démarrage, dès le boot, ce qui les en quelque sorte ``permanentes''.

\subsection{Sauvegarde des bases MySQL et PostgreSQL}
Les bases de données, que ce soit avec MariaDB ou PostgreSQL, peuvent être modifiées ou supprimées durant l'exécution, peu importe la raison (utilisateur malveillant, bug, erreur, ...). Pour cela, une sauvegarde de ces bases de données est un élément important de notre architecture.\\
Pour les sauvegardes de MariaDB donc de MySQL, il existe un commande qui permet de le faire automatiquement, mais celle-ci est téléchargable uniquement avec le gestionnaire de paquet ``aptitude". \\
Il faut donc l'installer avec:
\begin{lstlisting}[language=bash] 
    $ apt-get install aptitude
\end{lstlisting}

Une fois le gestionnaire aptitude installé on peut alors installer le paquet ``automysqlbackup":
\begin{lstlisting}[language=bash] 
    $ aptitude install automysqlbackup 
\end{lstlisting}

Par défaut, automysqlbackup crée un fichier ``/etc/default/automysqlbackup", qui est son fichier de configuration. Nous avons coupé ce fichier et avons mis le notre dans ``/etc/automysqlbackup/myserver.conf". Une fois cette étape passée, il suffit de démarrer la sauvegarde automatique avec automysqlbackup:
\begin{lstlisting}[language=bash] 
    $ automysqlbackup myserver.conf
\end{lstlisting}

Après avoir laissé le temps aux sauvegardes de s'effectuer sur les différents jours de la semaine, on peut alors voir les sauvegardes au format ``gz" donc compressées sous ``/var/lib/automysqlbackup/(daily, weekly, monthly)/dbtest":
\begin{figure}[H]
\centerline{ \includegraphics[width=18cm]{images/automysqlbackup.png}}
\caption{Sauvegarde de MySQL.}
\label{fig}
\end{figure}
On voit que chaque jour possède un sauvegarde, de même pour les semaines et le mois.

Pour ce qui est de la sauvegarde de la base de données PostegreSQL, nous avons utilisé crontab (pour la réaliser périodiquement), pg\_dumpall permettant de sortir en script le contenu intégral des bases de données (l'exécution du script restore l'état des bases) et zip afin de compreser le fichier produit par pg\_dumpall dans le but d'économiser de la place sur le disque dur. Voici l'ensemble des commandes que nous avons tapé:
\begin{lstlisting}[language=bash] 
    $ mkdir -p /backups/postgresql
    $ chown postgre /backups/postsresql/
    $ su - postgre
    postgres=# crontab -e 
        0 0 * * 0 pg_dumpall -U postgres | gzip > /backups/postgresql/save.gz
\end{lstlisting}
Pour les sauvegardes nous avons simplement créé le dossier ``/backups/postgresql", et donné les droits de ce dossier à l'utilisateur de PostgreSQL. Finalement, nous avons ajouté dans le fichier crontab sur le compte de l'utilisateur que la sauvegarde sera effectuée tous les dimanches à minuit et de compresser la sauvegarde pour l'envoyer dans le fichier ``save.gz".

\subsection{Les sudoers}
Sudo est un utilitaire de ligne de commande qui permet aux utilisateurs de confiance d'exécuter des commandes en tant qu'un autre utilisateur, par défaut root qui possède l'entièreté des droits sur la machine.\\
Dans la continuité de notre serveur web, nous souhaitons permettre à un webmaster de modifier la configuration d'apache et qu'il puisse relancer le serveur en cas de panne.
Pour cela, nous allons utiliser un système courant sous linux: sudo. Nous commençons par installer le paquets correspondant avec:
\begin{lstlisting}[language=bash] 
    $ apt-get install sudo
\end{lstlisting}

Une fois installé, il faut ajouter l'utilisateur ou le groupe dans le fichier des sudoers. Pour ce faire, on peut se rendre dans ce fichier de 2 façons différentes: avec la commande ``visudo" ou  directement dans le fichier en question ``/etc/sudoers" (non recommandé). Pour rappel l'utilisateur qui représente notre webmaster est ``dev1". Dans le fichier des sudoers nous avons rajouté une ligne, qui est la dernière de ce fichier.
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/sudoers.png}}
\caption{Contenu du fichier pour les sudoers.}
\label{fig25}
\end{figure}
Cette ligne nous indique que l'utilisateur ``dev1" à tous les droits pour exécuter ``/usr/bin/nano" sur ``/etc/apache2/*" (modifier la configuration), ``etc/init.d/apache2 restart" et ``/usr/sbin/service apache2 restart" (redémarrer le service). Dorénavant il peut donc ajouter/supprimer tout ce qu'il souhaite dans ``/etc/apache2/" et peut redemarrer le serveur apache. Nous avons du utiliser le chemin absolu pour nano par exemple car sudo ne prends pas en compte le PATH lors de l'exécution des commandes.

\section{Mise en place d'un domaine Samba/LDAP}
Dans cette section nous allons expliquer les différentes étapes de mise en place d'un domaine Samba/LDAP, pour constituer l'annuaire de notre entreprise et un système de fichiers correspondant. L'annuaire sera composé d'informations comme le nom, le prénom et le mail, mais il va également permettre de partager des ressources entre  utilisateurs. Pour l'ensemble de la configuration du domaine Samba/LDAP, nous avons utilisé un fichier zip qui était à notre disposition: \\``http://kundera/licence3/SystemesEtReseaux2/TP/FichiersconfTp3.zip".

\subsection{Mise en place de LDAP}
LDAP ou Lightweight Directory Access Protocol est un protocole d'accès à un annuaire (tcp/ip), il existe également OpenLDAP qui est la version libre du protocole. C'est un structure arborescente constituée d'entrées nommées D.I.T. Chaque entrée est un ensemble d'attributs, un attribut est un type, c'est-à-dire un nom, une description et une ou plusieurs valeurs. Les attributs sont définis dans des schémas. Pour débuter la mise en place de LDAP, il faut l'installer avec:
\begin{lstlisting}[language=bash] 
    $ apt-get install slapd
\end{lstlisting}
Après l'installation un affichage en mode texte se lance et nous demande différentes informations telles que: le nom de domaine, le nom de l'organisation et le mot de passe du root. Après les informations renseignées, nous avons copié le fichier de configuration ``slapd.conf" qui était mis à notre disposition à la place de ``/etc/ldap/slapd.conf":
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/slapdConf1.png}}
\caption{Contenu du fichier de configuration slapd partie 1.}
\label{fig}
\end{figure}
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/slapdConf2.png}}
\caption{Contenu du fichier de configuration slapd partie 2.}
\label{fig}
\end{figure}
Dans la partie 1 du fichier de configuration, nous avons inclus le schéma de Samba ``/etc/ldap/schema/samba.schema" mais nous en reparlerons plus tard. Dans la partie 1 et 2 du fichier de configuration nous avons remplacé les informations ``dc=dijon" par ``dc=atlantide" et dans la partie 2 nous avons définit l'accès à l'annuaire en lui donnant un suffix et un utilisateur root. Il est important de savoir que l'élément ``c" désigne ``country'' afin de définir un rayonnement international, ``dc" désigne ``Domain Component'' et est suffisant pour une entreprise à caractère régional. Les branches seront définies par l'élément ``ou" (``Organizational Unit'') pour classer les variables.\\

Afin de rendre ce fichier de configuration opérationnel il faut stopper le service LDAP, supprimer le fichier ``/etc/ldap/slapd.d" et redémarrer le service:
\begin{lstlisting}[language=bash] 
    $ systemctl stop slapd
    $ rm /etc/ldap/slapd.d
    $ systemctl start slapd
\end{lstlisting}

Nous allons désormais parametrer notre machine afin qu'elle exploite les données de notre annuaire et pour cela nous avons donc installé le paquet qui permet de gérer ceci:
\begin{lstlisting}[language=bash] 
    $ apt-get install libnss-ldap
\end{lstlisting}
Voici le contenu du fichier de configuration associé (``/etc/libnss-ldap.conf"):
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/libnssldap.png}}
\caption{Contenu du fichier de configuration libnss.}
\label{fig}
\end{figure}

\subsection{Mise en place de Samba}
Samba est une application libre qui tourne sous Linux et qui permet de créer un serveur de fichiers en s'appuyant sur l'implémentation du protocole SMB. Nous avons réaliser l'installation de samba via la commande: 
\begin{lstlisting}[language=bash] 
    $ apt-get install smbldap-tools
\end{lstlisting}
Comme pour LDAP, nous sommes repartis des éléments que nous avions en notre possession pour configurer Samba:
\begin{lstlisting}[language=bash] 
    $ mv smbldap_bind.conf /etc/smbldap-tools/

\end{lstlisting}
Le fichier contient:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/smbldapBindConf.png}}
\caption{Contenu du fichier de configuration smbldap bind.}
\label{fig}
\end{figure}
Dans cette configuration nous indiquons les informations relatives au DIT déterminé précédemment avec LDAP. 
\par
Viens ensuite la configuration d'un second fichier bien plus conséquent: le fichier ``/etc/smbldap-tools/smbldap.conf". Dans ce fichier, il faut encore une fois renseigner les Domain Component, c'est-à-dire le ``dc=agence,dc=atlantide". De plus, nous avons également renseigné le nom de domaine samba ``agenceatlantide". Nous avons également renseigné le SID, qui est un identifiant de sécurité utilisé pour identifier les ressources et les personnes sur un réseau. Nous avons pu le récupérer avec la commande:
\begin{lstlisting}[language=bash] 
    $ net getlocalsid
\end{lstlisting}
Et finalement voici à quoi ressemble la partie sur la configuration générale avec le SID et le nom de domaine renseigné:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/smbldapSID.png}}
\caption{Contenu du fichier de configuration smbldap.}
\label{fig}
\end{figure}

Nous allons aborder la notion de ressources partagées ainsi que le paramétrage du service Samba. Que ce soit pour la configuration du service samba ou pour la configuration des ressources à partager, tout est dans le fichier ``/etc/samba/smb.conf".
Dans un premier temps, expliquons le début du fichier, en particulier la configuration du service Samba:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/smbConf.png}}
\caption{Configuration du service Samba.}
\label{fig}
\end{figure}
Nous voyons au début l'authentification avec LDAP créée et parametrée auparavant. L'authentification est mise en place avec différents paramètres tels que: le suffix LDAP ``dc=agence,dc=atlantide", les suffix des utilisateurs et des groupes (``ou=Users'' et ``ou=Groups"). De plus, nous pouvoir voir qu'il y a une synchronisation automatique de tous les mots de passe d'un utilisateur, mais également une table d'encodage des caractères qui sont les mêmes que Windows. Le workgroup a été défini comme le nom de domaine ``agenceatlantide". Pour terminer avec cette partie, le ``netbios name" qui définit le nom du serveur a été défini à ``agenceatlantide".\\

Pour l'authentification via ldap, il faut installer le paquet: ``libpam-ldapd" avec le gestionnaire de paquets ``apt-get" que nous avons déjà utilisé à de nombreuses reprises.\\

Dans un second temps concentrons-nous sur le partage des ressources.
Les lignes dans la partie ``Share Definitions" déclarent nos partages:
\begin{figure}[H]
\centerline{ \includegraphics[width=15cm]{images/smbRessourcePartager.png}}
\caption{Partage des ressources samba.}
\label{fig}
\end{figure}
Pour expliquer, [homes/public] spécifie le nom du partage entre ``[]": c'est le nom qui devra être utilisé pour accéder au partage. Le paramètre comment est une description du partage, path est le chemin vers le dossier à partager sur le serveur. Le ``read only = no" nous dit que le partage n'est pas accessible uniquement pour la lecture seule. De plus, les fichiers sont éditables: ``writable = yes". Le fait que ``browsable" ne soit pas activé rend le partage masqué si on liste les partages du serveur avec un hôte distant. Pour le partage ``homes" le directory mask et create mask ont tous les 2 la valeur 0700 qui représente les permissions pour les groupes et les répertoires. 

Une fois la configuration terminée, il faut sauvegarder le fichier et redémarrer le service Samba:
\begin{lstlisting}[language=bash] 
    $ systemctl restart smbd
\end{lstlisting}

On souhaite dorénavant appliquer les changements dans les données et activer le lien entre samba et ldap, ce que nous faisons avec ``smbldap-populate". La commande smbldap-populate aide à remplir un serveur LDAP en ajoutant les entrées nécessaires: suffixe de base, unités d'organisation pour les utilisateurs, les groupes et les ordinateurs, les utilisateurs intégrés: administrateur, invité et les groupes intégrés. Ce paquet est utilisable via la commande:
\begin{lstlisting}[language=bash] 
    $ smbldap-populate
\end{lstlisting}

Samba et LDAP sont configurés, nous avons peuplé l'annuaire Samba. Il est temps de créer nos groupes et nos utilisateurs. Dans sa configuration par défaut, Samba dispose d'un partage nommé [homes]. En fait, il ne s'agit pas réellement d'un partage nommé ``homes" mais cette configuration spécifique permet de créer un partage personnel pour chaque utilisateur qui se connecte sur notre machine Linux. Le groupe ``public" que nous avons déclaré dans la configuration n'existe pas. Nous allons créer le groupe, ainsi que 2 utilisateurs nommés ``smbtest" et ``smbtest2" et qui seront membres de ce groupe. 
Les groupes sur Samba sont créé via la commande:
\begin{lstlisting}[language=bash] 
    $ groupadd nom_groupe
    $ groupadd public
\end{lstlisting}
Le partage ``public" est le partage de Samba qui permet de partager les fichiers entre les utilisateurs.\\

Pour samba il faut d'abord ajouter l'utilisateur dans ldap avec la commande:
\begin{lstlisting}[language=bash] 
    $ smbldap-useradd -a -m user
    $ smbldap-useradd -a -m smbtest
    $ smbldap-useradd -a -m smbtest2
\end{lstlisting}
Puis dans unix avec:
\begin{lstlisting}[language=bash] 
    $ useradd user
    $ useradd smbtest
    $ useradd smbtest2
\end{lstlisting}

Il ne faut également pas oublier de mettre le mot de passe de l'utilisateur en question, le mot de passe de samba est configurable via: 
\begin{lstlisting}[language=bash] 
    $ smbldap-passwd
\end{lstlisting}
Et pour unix simplement via:
\begin{lstlisting}[language=bash] 
    $ useradd user
\end{lstlisting}
Les mots de passe peuvent être les mêmes ou non cela dépend du bon vouloir de chacun et du niveau de sécurité que vous souhaitez instaurer. \\

Finalement il suffit de mettre les bons droits au nouveau home créé, afin de définir le propriétaire du répertoire:
\begin{lstlisting}[language=bash] 
    $ chown user /home/smb
    $ chown smbtest /home/smbtest
    $ chown smbtest2 /home/smbtest2
\end{lstlisting}

Le partage ``public" va être hébergé à l'emplacement ``/srv/smbshared" de notre serveur. Commençons par créer le dossier:
\begin{lstlisting}[language=bash] 
    $ mkdir /srv/smbshared
\end{lstlisting}
Ensuite, on va attribuer le groupe ``public" comme groupe propriétaire de ce dossier:
\begin{lstlisting}[language=bash] 
    $ chgrp -R public /srv/smbshared/
\end{lstlisting}
Puis, nous allons ajouter les droits de lecture/écriture à ce groupe sur ce dossier:
\begin{lstlisting}[language=bash] 
    $ chmod -R g+rw /srv/smbshared/
\end{lstlisting}

Les groupes et utilisateurs une fois créé sont visibles via les commandes:
\begin{lstlisting}[language=bash] 
    $ nano /etc/group
    $ nano /etc/passwd
\end{lstlisting}
Via la première commande nous avons seulement accès aux groupes sur le serveur local, si des groupes sont créés uniquement sur LDAP où Samba alors on peut les afficher avec:
\begin{lstlisting}[language=bash] 
    $ getent group
\end{lstlisting}

Si l'on souhaite afficher toutes les informations concernant Samba et LDAP un commande existe:
\begin{lstlisting}[language=bash] 
    $ slapcat
\end{lstlisting}

Dans ``/etc/ldap/schema/samba.schema", nous avons eu besoin d'ajouter le schéma de Samba dans LDAP, mais également de réadapter notre matrice de filtrage en rajoutant les lignes qui traite Samba, c'est-à-dire les ports: 139 (authentification), et 389 (active directory).\\

Finalement pour vérifier que les utilisateurs créés peuvent accéder à distance au dossier partagé et à leurs répertoires homes, nous avons monté sur un client les partages correspondant dans le système de fichier à partir de l'interface graphique. Nous pouvons également nous connecter avec la commande smb-client.

\subsection{Sauvegarde automatique de l'annuaire}
Pour ce qui est de la sauvegarde automatique de notre annuaire, nous avons utilisé crontab (pour la réaliser périodiquement) ainsi que ``slapcat" permettant d'avoir le contenu intégral du LDAP puis encore une fois zip afin de compresser le fichier produit dans le but d'économiser de la place sur le disque dur. Pour la sauvegarde nous avons simplement créé le dossier ``/backups/smbsldap". Finalement, nous avons ajouté dans le fichier crontab que le cron sera effectué tous les dimanches à minuit, afin de compresser les informations pour les envoyer dans le fichier ``save.gz". 
\begin{lstlisting}[language=bash] 
    $ crontab -e 0 0 * * 0 slapcat | gzip  > /backups/smbsldap/save.gz
\end{lstlisting}

\section{Conclusion}
Pour conclure sur l'ensemble de notre installation, nous avons installé Linux sans interface graphique, puis paramétré le réseau global avec la mise en place un DNS. Nous avons également installé, paramétré et testé un serveur LAMP et finalement le duo LDAP/Samba. Tout ceci a demandé de nombreuses heures de travail mais nous avons acquis beaucoup de connaissances. Comme nous avons pu le montrer durant les différente étapes, chaque partie a été minutieusement traitée dans le but d'avoir un ensemble fonctionnel. Pour finir, on pourrait également imaginer compléter notre infrastructure avec l'installation d'un serveur FTP ou mail par exemple.

\section{Annexe}
\listoffigures  
\end{document}
